{"cells":[{"cell_type":"markdown","metadata":{"id":"lqt_yzRy16Wj"},"source":["## Task\n","\n","In this compulsory task you will clean the country column and parse the date column in the **store_income_data_task.csv** file."]},{"cell_type":"code","execution_count":4,"metadata":{"id":"vBP3WN2O16Wp"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>store_name</th>\n","      <th>store_email</th>\n","      <th>department</th>\n","      <th>income</th>\n","      <th>date_measured</th>\n","      <th>country</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>Cullen/Frost Bankers, Inc.</td>\n","      <td>NaN</td>\n","      <td>Clothing</td>\n","      <td>$54438554.24</td>\n","      <td>4-2-2006</td>\n","      <td>United States/</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>Nordson Corporation</td>\n","      <td>NaN</td>\n","      <td>Tools</td>\n","      <td>$41744177.01</td>\n","      <td>4-1-2006</td>\n","      <td>Britain</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>Stag Industrial, Inc.</td>\n","      <td>NaN</td>\n","      <td>Beauty</td>\n","      <td>$36152340.34</td>\n","      <td>12-9-2003</td>\n","      <td>United States</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>FIRST REPUBLIC BANK</td>\n","      <td>ecanadine3@fc2.com</td>\n","      <td>Automotive</td>\n","      <td>$8928350.04</td>\n","      <td>8-5-2006</td>\n","      <td>Britain/</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>Mercantile Bank Corporation</td>\n","      <td>NaN</td>\n","      <td>Baby</td>\n","      <td>$33552742.32</td>\n","      <td>21-1-1973</td>\n","      <td>United Kingdom</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   id                   store_name         store_email  department  \\\n","0   1   Cullen/Frost Bankers, Inc.                 NaN    Clothing   \n","1   2          Nordson Corporation                 NaN       Tools   \n","2   3        Stag Industrial, Inc.                 NaN      Beauty   \n","3   4          FIRST REPUBLIC BANK  ecanadine3@fc2.com  Automotive   \n","4   5  Mercantile Bank Corporation                 NaN        Baby   \n","\n","         income date_measured          country  \n","0  $54438554.24      4-2-2006   United States/  \n","1  $41744177.01      4-1-2006          Britain  \n","2  $36152340.34     12-9-2003    United States  \n","3   $8928350.04      8-5-2006         Britain/  \n","4  $33552742.32     21-1-1973   United Kingdom  "]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","\n","\n","# Load up store_income_data.csv\n","df = pd.read_csv('store_income_data_task.csv')\n","df.head()\n"]},{"cell_type":"markdown","metadata":{"id":"ItqLwumA16Wr"},"source":["1. Take a look at all the unique values in the \"country\" column. Then, convert the column to lowercase and remove any trailing white spaces."]},{"cell_type":"code","execution_count":28,"metadata":{"id":"sLkzt4Hr16Wr"},"outputs":[{"data":{"text/plain":["array(['united states/', 'britain', 'united states', 'britain/',\n","       'united kingdom', 'u.k.', 'sa', 'u.k/', 'america', nan, 's.a.',\n","       'england', 'uk', 's.a./', 'u.k', 'america/', 'sa.', '', 'uk.',\n","       'england/', 'united states of america', 'uk/', 'sa/', 'england.',\n","       'america.', 's.a..', 'united states of america.',\n","       'united states of america/', 'united states.',\n","       's. africasouth africa', 'britain.', '/', 'united kingdom.',\n","       's. africasouth africa/', 'united kingdom/',\n","       's. africasouth africa.', '.'], dtype=object)"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["df['country'] = df['country'].str.lower().str.strip()\n","df['country'].unique()\n"]},{"cell_type":"markdown","metadata":{"id":"P6dcDc4P16Ws"},"source":["2. Note that there should only be three separate countries. Eliminate all variations, so that 'South Africa', 'United Kingdom' and 'United States' are the only three countries."]},{"cell_type":"code","execution_count":72,"metadata":{"id":"qeV3CxMR16Ws"},"outputs":[{"data":{"text/plain":["array(['united states', 'united kingdom', 'south africa', nan, '', '/',\n","       '.'], dtype=object)"]},"execution_count":72,"metadata":{},"output_type":"execute_result"}],"source":["df.replace(\"sa\", \"south africa\", inplace=True)\n","df.replace(\"s.a\", \"south africa\", inplace=True)\n","df.replace(\"s.a.\", \"south africa\", inplace=True)\n","df.replace(\"s.a./\", \"south africa\", inplace=True)\n","df.replace(\"sa.\", \"south africa\", inplace=True)\n","df.replace(\"sa/\", \"south africa\", inplace=True)\n","df.replace(\"s.a..\", \"south africa\", inplace=True)\n","df.replace(\"s. africasouth africa.\", \"south africa\", inplace=True)\n","df.replace(\"s. africasouth africa\", \"south africa\", inplace=True)\n","df.replace(\"s. africasouth africa/\", \"south africa\", inplace=True)\n","df.replace(\"britain\", \"united kingdom\", inplace=True)\n","df.replace(\"u.k\", \"united kingdom\", inplace=True)\n","df.replace(\"uk/\", \"united kingdom\", inplace=True)\n","df.replace(\"england\", \"united kingdom\", inplace=True)\n","df.replace(\"uk.\", \"united kingdom\", inplace=True)\n","df.replace(\"u.k.\", \"united kingdom\", inplace=True)\n","df.replace(\"england/\", \"united kingdom\", inplace=True)\n","df.replace(\"u.k/\", \"united kingdom\", inplace=True)\n","df.replace(\"britain/\", \"united kingdom\", inplace=True)\n","df.replace(\"united kingdom/\", \"united kingdom\", inplace=True)\n","df.replace(\"uk\", \"united kingdom\", inplace=True)\n","df.replace(\"britain.\", \"united kingdom\", inplace=True)\n","df.replace(\"united kingdom.\", \"united kingdom\", inplace=True)\n","df.replace(\"england.\", \"united kingdom\", inplace=True)\n","df.replace(\"america\", \"united states\", inplace=True)\n","df.replace(\"america.\", \"united states\", inplace=True)\n","df.replace(\"united states of america\", \"united states\", inplace=True)\n","df.replace(\"united states of america.\", \"united states\", inplace=True)\n","df.replace(\"united states of america/\", \"united states\", inplace=True)\n","df.replace(\"united states.\", \"united states\", inplace=True)\n","df.replace(\"united states/\", \"united states\", inplace=True)\n","df.replace(\"america/\", \"united states\", inplace=True)\n","df['country'].unique()"]},{"cell_type":"markdown","metadata":{"id":"UJZDMTwP16Ws"},"source":["3. Create a new column called `days_ago` in the DataFrame that is a copy of the 'date_measured' column but instead it is a number that shows how many days ago it was measured from the current date. Note that the current date can be obtained using `datetime.date.today()`."]},{"cell_type":"code","execution_count":77,"metadata":{"id":"gMJbN84P16Wt"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>store_name</th>\n","      <th>store_email</th>\n","      <th>department</th>\n","      <th>income</th>\n","      <th>date_measured</th>\n","      <th>country</th>\n","      <th>days_ago</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>Cullen/Frost Bankers, Inc.</td>\n","      <td>NaN</td>\n","      <td>Clothing</td>\n","      <td>$54438554.24</td>\n","      <td>4-2-2006</td>\n","      <td>united states</td>\n","      <td>4-2-2006</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>Nordson Corporation</td>\n","      <td>NaN</td>\n","      <td>Tools</td>\n","      <td>$41744177.01</td>\n","      <td>4-1-2006</td>\n","      <td>united kingdom</td>\n","      <td>4-1-2006</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>Stag Industrial, Inc.</td>\n","      <td>NaN</td>\n","      <td>Beauty</td>\n","      <td>$36152340.34</td>\n","      <td>12-9-2003</td>\n","      <td>united states</td>\n","      <td>12-9-2003</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>FIRST REPUBLIC BANK</td>\n","      <td>ecanadine3@fc2.com</td>\n","      <td>Automotive</td>\n","      <td>$8928350.04</td>\n","      <td>8-5-2006</td>\n","      <td>united kingdom</td>\n","      <td>8-5-2006</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>Mercantile Bank Corporation</td>\n","      <td>NaN</td>\n","      <td>Baby</td>\n","      <td>$33552742.32</td>\n","      <td>21-1-1973</td>\n","      <td>united kingdom</td>\n","      <td>21-1-1973</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   id                   store_name         store_email  department  \\\n","0   1   Cullen/Frost Bankers, Inc.                 NaN    Clothing   \n","1   2          Nordson Corporation                 NaN       Tools   \n","2   3        Stag Industrial, Inc.                 NaN      Beauty   \n","3   4          FIRST REPUBLIC BANK  ecanadine3@fc2.com  Automotive   \n","4   5  Mercantile Bank Corporation                 NaN        Baby   \n","\n","         income date_measured         country   days_ago  \n","0  $54438554.24      4-2-2006   united states   4-2-2006  \n","1  $41744177.01      4-1-2006  united kingdom   4-1-2006  \n","2  $36152340.34     12-9-2003   united states  12-9-2003  \n","3   $8928350.04      8-5-2006  united kingdom   8-5-2006  \n","4  $33552742.32     21-1-1973  united kingdom  21-1-1973  "]},"execution_count":77,"metadata":{},"output_type":"execute_result"}],"source":["df['days_ago'] = df['date_measured']\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3.10.0 ('phd')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]"},"vscode":{"interpreter":{"hash":"63d17dc58a06b6a6d4136fb13c245dafcf53668da37b1c3052c24d689135f5bb"}}},"nbformat":4,"nbformat_minor":0}
